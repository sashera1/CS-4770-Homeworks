{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sashera1/CS-4770-Homeworks/blob/main/Assignment_1_release.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS 4770 Natural Language Processing (Fall 2025)\n",
        "\n",
        "## Assignment 1: PyTorch Warm-Up\n",
        "\n",
        "In this assignment, you will use PyTorch to implement and train a simple neural network on SST-2 dataset. This assignment will help you get familiar with the PyTorch library and the basic concepts of neural networks."
      ],
      "metadata": {
        "id": "qM0UJD7W5Y79"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S5lc89tY5LNf",
        "outputId": "ced7cb59-7252-45a4-a33c-c41a7300e96a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7901d93a0690>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(99)\n",
        "torch.manual_seed(99)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Python Lists and NumPy Arrays (5 pts).\n",
        "\n",
        "TODO: Create a Python list of the first 12 cube numbers $(1, 8, 27, â€¦, 1728)$.\n",
        "\n",
        "Convert this list to a NumPy array and reshape it into a $3\\times4$ matrix. Print out the matrix as a 2-dimensional array."
      ],
      "metadata": {
        "id": "EUga99_O5zEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cube_numbers = []\n",
        "for i in range(12):\n",
        "  base = i+1\n",
        "  val = base ** 3\n",
        "  cube_numbers.append(val)\n",
        "cube_matrix = np.array(cube_numbers)\n",
        "cube_matrix = cube_matrix.reshape(3,4)\n",
        "print(cube_matrix)"
      ],
      "metadata": {
        "id": "rIf9qUWezNdm",
        "outputId": "6b4d87b6-d87e-4cc9-a550-dbe393230963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   1    8   27   64]\n",
            " [ 125  216  343  512]\n",
            " [ 729 1000 1331 1728]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: PyTorch Tensors and Operations (11 pts)\n",
        "\n",
        "Convert the NumPy array from Question 1 into a PyTorch float32 tensor and perform the following operations. The following operations must be done using PyTorch interfaces.\n",
        "\n",
        "TODO: Subtract 5 from every element and print out the mean of all elements. (5 pts)"
      ],
      "metadata": {
        "id": "XCYQQGs96MSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_of_cubes = torch.from_numpy(cube_matrix).to(torch.float32)\n",
        "tensor_of_cubes = tensor_of_cubes - 5.0\n",
        "print(torch.mean(tensor_of_cubes).item())"
      ],
      "metadata": {
        "id": "Om74uiYL6hiR",
        "outputId": "ef9145a1-e929-4fd2-9050-70d63a114527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "502.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Create a new $4 \\times 3$ tensor by transposing the original tensor. Print out the transposed tensor. (3 pts)"
      ],
      "metadata": {
        "id": "Ic-Dw4Um4_Db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_of_cubes_t = (tensor_of_cubes + 5).t() #get back the original tensor\n",
        "print(tensor_of_cubes_t)"
      ],
      "metadata": {
        "id": "GBmy3kiq4-kc",
        "outputId": "5bff31dc-180a-4a31-ac79-7f1487404b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e+00, 1.2500e+02, 7.2900e+02],\n",
            "        [8.0000e+00, 2.1600e+02, 1.0000e+03],\n",
            "        [2.7000e+01, 3.4300e+02, 1.3310e+03],\n",
            "        [6.4000e+01, 5.1200e+02, 1.7280e+03]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Perform matrix multiplication between the original tensor and the transposed tensor. Print out the result. (3 pts)"
      ],
      "metadata": {
        "id": "9_lpD-8C5FCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_matrix = tensor_of_cubes @ tensor_of_cubes_t\n",
        "print(product_matrix)"
      ],
      "metadata": {
        "id": "INGdzlA95GxT",
        "outputId": "6ee45a53-65d3-4672-a68d-eb08cba95db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.3900e+03, 3.7902e+04, 1.3132e+05],\n",
            "        [4.3382e+04, 4.3609e+05, 1.6245e+06],\n",
            "        [1.5476e+05, 1.6424e+06, 6.2650e+06]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: SST-2 Sentiment Classification (30 pts)\n",
        "\n",
        "In this question, you will build a simple neural network to predict whether a sentence expresses positive or negative sentiment. We will use the SST-2 (Stanford Sentiment Treebank, Binary version) dataset. This dataset is widely used in NLP research and is available through the HuggingFace datasets library."
      ],
      "metadata": {
        "id": "ra8MwUOZ6rwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install HuggingFace datasets library."
      ],
      "metadata": {
        "id": "z4-BqZRF8bvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Y-w2u7Oc7lmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess the dataset. (You don't need to modify this cell.)"
      ],
      "metadata": {
        "id": "pUlOwwFG8htm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "np.random.seed(99)\n",
        "torch.manual_seed(99)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Function that preprocesses the string\n",
        "    \"\"\"\n",
        "    preprocessed_text = text.lower()\n",
        "    return preprocessed_text\n",
        "\n",
        "# Load SST-2 dataset from HuggingFace\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# Extract train, validation and test sets\n",
        "train_data = dataset[\"train\"]\n",
        "val_data = dataset[\"validation\"]\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "# Process training data\n",
        "train_contents = [preprocess_text(example[\"sentence\"]) for example in train_data]\n",
        "train_labels = [example[\"label\"] for example in train_data]\n",
        "\n",
        "# Process validation data\n",
        "val_contents = [preprocess_text(example[\"sentence\"]) for example in val_data]\n",
        "val_labels = [example[\"label\"] for example in val_data]\n",
        "\n",
        "# Process test data (note: SST-2 test set doesn't have labels, using validation as test)\n",
        "test_contents = [preprocess_text(example[\"sentence\"]) for example in val_data]\n",
        "test_labels = [example[\"label\"] for example in val_data]\n",
        "\n",
        "sentiments = [\"Negative\", \"Positive\"]\n",
        "\n",
        "print(f\"Train size: {len(train_contents)}, \"\n",
        "      f\"\\nVal size: {len(val_contents)}, \"\n",
        "      f\"\\nTest size: {len(test_contents)}\")\n",
        "\n",
        "# show the first review and its sentiment label\n",
        "print(\"Sentence: \", train_data[0][\"sentence\"])\n",
        "print(\"Sentiment: \", sentiments[train_labels[0]])"
      ],
      "metadata": {
        "id": "xU6zwfeJ8jBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the SST-2 dataset class. (You don't need to modify this cell.)"
      ],
      "metadata": {
        "id": "wUb0BWnO8sP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the text data using CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "X_train = vectorizer.fit_transform(train_contents).toarray()\n",
        "X_val = vectorizer.transform(val_contents).toarray()\n",
        "X_test = vectorizer.transform(test_contents).toarray()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "class SST2Dataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = torch.tensor(texts, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx], self.labels[idx]\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataset = SST2Dataset(X_train, y_train)\n",
        "val_dataset = SST2Dataset(X_val, y_val)\n",
        "test_dataset = SST2Dataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "CC6x0hDQ8uSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Implement a simple two-layer neural network using PyTorch's `nn.Module` for binary classification. The network should have:\n",
        "\n",
        "- An input layer of **input\\_dim** features.\n",
        "- One hidden layer with 64 neurons and **ReLU** activation.\n",
        "- An output layer with 1 neuron and **Sigmoid** activation.\n",
        "\n",
        "Then initialize the model where **input\\_dim** equals the shape of the data in **X\\_train**, use the Binary Entropy loss function, and the Adam optimizer with 0.001 learning rate. (10 pts)"
      ],
      "metadata": {
        "id": "W33c3hjP6iG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "       pass\n",
        "\n",
        "# TODO: initialize the model, loss and optimizer\n",
        "model = None\n",
        "criterion = None\n",
        "optimizer = None"
      ],
      "metadata": {
        "id": "aYlK1euG7Vc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Train the neural network for 10 epochs, and print out the training loss and accuracy on the training set at the end of each epoch. (10 pts)"
      ],
      "metadata": {
        "id": "gLVErJk07XhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # TODO: Complete the training loop, update the training loss and accuracy\n",
        "    for i, (texts, labels) in enumerate(train_loader):\n",
        "        pass\n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Train Loss: {train_loss:.4f}, \"\n",
        "          f\"Train Acc: {train_acc:.4f}, \")"
      ],
      "metadata": {
        "id": "stCPhyP-7baN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Evaluate the test set and report the test accuracy. (10 pts)"
      ],
      "metadata": {
        "id": "DGHG8jDY7cHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_correct = 0\n",
        "with torch.no_grad():\n",
        "    for i, (texts, labels) in enumerate(test_loader):\n",
        "        pass\n",
        "test_acc = test_correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "_WZTc1f67fpW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}